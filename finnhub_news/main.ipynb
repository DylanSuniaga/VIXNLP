{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('data/finnhub_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>headline</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tracking Ray Dalio's Bridgewater Associates 13...</td>\n",
       "      <td>Bridgewater Associates' Q3 moves: Portfolio va...</td>\n",
       "      <td>SeekingAlpha</td>\n",
       "      <td>https://finnhub.io/api/news?id=f3260216083646e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Madison Sustainable Equity Fund Q4 2024 Invest...</td>\n",
       "      <td>The S&amp;P 500 ended 2024 with a 25% gain for the...</td>\n",
       "      <td>SeekingAlpha</td>\n",
       "      <td>https://finnhub.io/api/news?id=03de51df45863f6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Broadcom Is Threatening AMD's Data Center Oppo...</td>\n",
       "      <td>Explore Advanced Micro Devices, Inc.'s journey...</td>\n",
       "      <td>SeekingAlpha</td>\n",
       "      <td>https://finnhub.io/api/news?id=a8f77b9fa84d454...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple's iPhone 16E Strategy</td>\n",
       "      <td>Nabila Popal, senior research director at the ...</td>\n",
       "      <td>Finnhub</td>\n",
       "      <td>https://finnhub.io/api/news?id=a8bd7172af2bd15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple’s iPhone 16e Is a Big Moment for the Com...</td>\n",
       "      <td>Apple’s iPhone 16e Is a Big Moment for the Com...</td>\n",
       "      <td>MarketWatch</td>\n",
       "      <td>https://finnhub.io/api/news?id=1a3f05459e859d2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date symbol                                           headline  \\\n",
       "0  2025-02-20   AAPL  Tracking Ray Dalio's Bridgewater Associates 13...   \n",
       "1  2025-02-20   AAPL  Madison Sustainable Equity Fund Q4 2024 Invest...   \n",
       "2  2025-02-20   AAPL  Broadcom Is Threatening AMD's Data Center Oppo...   \n",
       "3  2025-02-20   AAPL                        Apple's iPhone 16E Strategy   \n",
       "4  2025-02-20   AAPL  Apple’s iPhone 16e Is a Big Moment for the Com...   \n",
       "\n",
       "                                             summary        source  \\\n",
       "0  Bridgewater Associates' Q3 moves: Portfolio va...  SeekingAlpha   \n",
       "1  The S&P 500 ended 2024 with a 25% gain for the...  SeekingAlpha   \n",
       "2  Explore Advanced Micro Devices, Inc.'s journey...  SeekingAlpha   \n",
       "3  Nabila Popal, senior research director at the ...       Finnhub   \n",
       "4  Apple’s iPhone 16e Is a Big Moment for the Com...   MarketWatch   \n",
       "\n",
       "                                                 url  \n",
       "0  https://finnhub.io/api/news?id=f3260216083646e...  \n",
       "1  https://finnhub.io/api/news?id=03de51df45863f6...  \n",
       "2  https://finnhub.io/api/news?id=a8f77b9fa84d454...  \n",
       "3  https://finnhub.io/api/news?id=a8bd7172af2bd15...  \n",
       "4  https://finnhub.io/api/news?id=1a3f05459e859d2...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert summaries to list first, then process each with FinBERT\n",
    "summaries = news_df['summary'].fillna('').astype(str).tolist()\n",
    "\n",
    "# Create lists to store sentiment scores and labels\n",
    "sentiment_scores = []\n",
    "sentiment_labels = []\n",
    "\n",
    "# Process each summary individually\n",
    "for summary in summaries:\n",
    "    result = pipe.predict(summary)[0]\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "    \n",
    "    # Store the label\n",
    "    sentiment_labels.append(label)\n",
    "    \n",
    "    # Calculate the modified score based on label\n",
    "    if label == 'positive':\n",
    "        sentiment_scores.append(score)\n",
    "    elif label == 'negative':\n",
    "        sentiment_scores.append(score * -1)\n",
    "    else:  # neutral\n",
    "        sentiment_scores.append(score / 10)\n",
    "\n",
    "# Add both the scores and labels to the DataFrame\n",
    "news_df['summary_sentiment'] = sentiment_scores\n",
    "news_df['sentiment_label'] = sentiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert headlines to list first, then process each with FinBERT\n",
    "headlines = news_df['headline'].fillna('').astype(str).tolist()\n",
    "\n",
    "# Create lists to store sentiment scores and labels\n",
    "headline_sentiment_scores = []\n",
    "headline_sentiment_labels = []\n",
    "\n",
    "# Process each headline individually\n",
    "for headline in headlines:\n",
    "    result = pipe.predict(headline)[0]\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "    \n",
    "    # Store the label\n",
    "    headline_sentiment_labels.append(label)\n",
    "    \n",
    "    # Calculate the modified score based on label\n",
    "    if label == 'positive':\n",
    "        headline_sentiment_scores.append(score)\n",
    "    elif label == 'negative':\n",
    "        headline_sentiment_scores.append(score * -1)\n",
    "    else:  # neutral\n",
    "        headline_sentiment_scores.append(score / 10)\n",
    "\n",
    "# Add both the scores and labels to the DataFrame\n",
    "news_df['headline_sentiment'] = headline_sentiment_scores\n",
    "news_df['headline_sentiment_label'] = headline_sentiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2025-02-20\n",
       "1       2025-02-20\n",
       "2       2025-02-20\n",
       "3       2025-02-20\n",
       "4       2025-02-20\n",
       "           ...    \n",
       "2830    2025-01-17\n",
       "2831    2025-01-16\n",
       "2832    2025-01-16\n",
       "2833    2025-01-16\n",
       "2834    2025-01-15\n",
       "Name: date, Length: 2835, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date value counts:\n",
      "date\n",
      "2025-02-05    194\n",
      "2025-02-19    181\n",
      "2025-02-10    169\n",
      "2025-02-18    161\n",
      "2025-02-14    159\n",
      "2025-02-13    155\n",
      "2025-02-11    144\n",
      "2025-02-20    141\n",
      "2025-02-07    139\n",
      "2025-01-15    136\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Date column data type: object\n",
      "Number of unique dates: 41\n",
      "Date range: 2020-07-22 to 2025-02-20\n",
      "\n",
      "After filtering:\n",
      "Number of rows: 2828\n",
      "Number of unique dates: 37\n",
      "Date range: 2025-01-15 00:00:00 to 2025-02-20 00:00:00\n",
      "\n",
      "Daily sentiment DataFrame:\n",
      "Shape: (37, 4)\n",
      "         date  avg_summary_sentiment  avg_headline_sentiment  \\\n",
      "0  2025-01-15               0.305992                0.243975   \n",
      "1  2025-01-16               0.137057                0.111931   \n",
      "2  2025-01-17               0.023022               -0.003805   \n",
      "3  2025-01-18               0.252645                0.046424   \n",
      "4  2025-01-19               0.200463                0.301068   \n",
      "\n",
      "   avg_overall_sentiment  \n",
      "0               0.274983  \n",
      "1               0.124494  \n",
      "2               0.009608  \n",
      "3               0.149534  \n",
      "4               0.250766  \n"
     ]
    }
   ],
   "source": [
    "# First, let's examine the date distribution in the original DataFrame\n",
    "print(\"Date value counts:\")\n",
    "print(news_df['date'].value_counts().head(10))\n",
    "\n",
    "# Check data types and potential issues\n",
    "print(\"\\nDate column data type:\", news_df['date'].dtype)\n",
    "print(\"Number of unique dates:\", news_df['date'].nunique())\n",
    "print(\"Date range:\", news_df['date'].min(), \"to\", news_df['date'].max())\n",
    "\n",
    "# Ensure dates are in the correct format\n",
    "# Convert the date column to datetime if it's not already\n",
    "news_df['date'] = pd.to_datetime(news_df['date'])\n",
    "\n",
    "# Filter to our expected date range (2025-01-15 to 2025-02-20)\n",
    "filtered_news_df = news_df[\n",
    "    (news_df['date'] >= '2025-01-15') & \n",
    "    (news_df['date'] <= '2025-02-20')\n",
    "]\n",
    "\n",
    "print(\"\\nAfter filtering:\")\n",
    "print(\"Number of rows:\", len(filtered_news_df))\n",
    "print(\"Number of unique dates:\", filtered_news_df['date'].nunique())\n",
    "print(\"Date range:\", filtered_news_df['date'].min(), \"to\", filtered_news_df['date'].max())\n",
    "\n",
    "# Now create daily sentiment with the filtered data\n",
    "daily_sentiment_df = filtered_news_df.groupby(filtered_news_df['date'].dt.date).agg({\n",
    "    'summary_sentiment': 'mean',\n",
    "    'headline_sentiment': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "daily_sentiment_df = daily_sentiment_df.rename(columns={\n",
    "    'summary_sentiment': 'avg_summary_sentiment',\n",
    "    'headline_sentiment': 'avg_headline_sentiment'\n",
    "})\n",
    "\n",
    "# Calculate overall average sentiment\n",
    "daily_sentiment_df['avg_overall_sentiment'] = (\n",
    "    daily_sentiment_df['avg_summary_sentiment'] + \n",
    "    daily_sentiment_df['avg_headline_sentiment']\n",
    ") / 2\n",
    "\n",
    "print(\"\\nDaily sentiment DataFrame:\")\n",
    "print(\"Shape:\", daily_sentiment_df.shape)\n",
    "print(daily_sentiment_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price         date       Open       High        Low      Close Volume\n",
      "Ticker                   ^VIX       ^VIX       ^VIX       ^VIX   ^VIX\n",
      "0       2025-01-02  17.209999  19.500000  16.959999  17.930000      0\n",
      "1       2025-01-03  17.660000  17.940001  16.110001  16.129999      0\n",
      "2       2025-01-06  16.770000  16.870001  15.710000  16.040001      0\n",
      "3       2025-01-07  16.480000  18.900000  15.790000  17.820000      0\n",
      "4       2025-01-08  17.910000  19.500000  17.370001  17.700001      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2025-01-01\"\n",
    "end_date = \"2025-02-20\"\n",
    "\n",
    "# Download VIX data\n",
    "vix_data = yf.download(\"^VIX\", start=start_date, end=end_date)\n",
    "\n",
    "# Extract needed columns\n",
    "vix_df = vix_data[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]].copy()\n",
    "\n",
    "# Convert index to a date column and reset index\n",
    "vix_df[\"date\"] = vix_df.index.date\n",
    "vix_df = vix_df.reset_index(drop=True)\n",
    "\n",
    "# Reorder columns to have date first\n",
    "vix_df = vix_df[[\"date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "\n",
    "# Print the first few rows to verify\n",
    "print(vix_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
